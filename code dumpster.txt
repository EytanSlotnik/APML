# import pickle
# f = open('data.txt','wb')
# pickle.dump(df,f)
# df = pickle.load(open('data.txt', 'rb'))



# from pandas_profiling import ProfileReport
# profile = ProfileReport(df)
# profile.to_file("data_report.html")

def encode_fire_size_class(df):
  """
  for each fire size category calculate mean and var and add respective columns
  :param df: data
  :return: data with added columns
  """
  temp = df.groupby(["FIRE_SIZE_CLASS"]).mean()["FIRE_SIZE"]
  df["FIRE_SIZE_CLASS_MEAN"] = df["FIRE_SIZE_CLASS"].map(temp)
  temp = df.groupby(["FIRE_SIZE_CLASS"]).var()["FIRE_SIZE"]
  df["FIRE_SIZE_CLASS_VAR"] = df["FIRE_SIZE_CLASS"].map(temp)
  return df


def add_rainfall_data(df):

    rainfall_data = pd.read_csv("daily_rainfall_flags_removed.csv")
    fips_code_to_abbreviation = {
        '01': 'AL',
        '02': 'AK',
        '04': 'AZ',
        '05': 'AR',
        '06': 'CA',
        '08': 'CO',
        '09': 'CT',
        '10': 'DE',
        '11': 'DC',
        '12': 'FL',
        '13': 'GA',
        '15': 'HI',
        '16': 'ID',
        '17': 'IL',
        '18': 'IN',
        '19': 'IA',
        '20': 'KS',
        '21': 'KY',
        '22': 'LA',
        '23': 'ME',
        '24': 'MD',
        '25': 'MA',
        '26': 'MI',
        '27': 'MN',
        '28': 'MS',
        '29': 'MO',
        '30': 'MT',
        '31': 'NE',
        '32': 'NV',
        '33': 'NH',
        '34': 'NJ',
        '35': 'NM',
        '36': 'NY',
        '37': 'NC',
        '38': 'ND',
        '39': 'OH',
        '40': 'OK',
        '41': 'OR',
        '42': 'PA',
        '44': 'RI',
        '45': 'SC',
        '46': 'SD',
        '47': 'TN',
        '48': 'TX',
        '49': 'UT',
        '50': 'VT',
        '51': 'VA',
        '53': 'WA',
        '54': 'WV',
        '55': 'WI',
        '56': 'WY',
    }
    rainfall_data["state_code"] = rainfall_data["state_code"].astype(str)
    rainfall_data["STATE_ABB"] = rainfall_data['state_code'].map(fips_code_to_abbreviation).astype(str)
    rainfall_data["date"]= pd.to_datetime(rainfall_data["date"])
    rainfall_data['MONTH'] = rainfall_data['date'].dt.month.astype(str)
    grouped_df = rainfall_data.groupby(['STATE_ABB','MONTH'])
    mean_df = grouped_df.mean().reset_index().filter(items=['STATE_ABB','MONTH','rainfall'])

    def add_state_abb_col(df):
        # Extract only the state columns
        state_cols = [col for col in df.columns if col.startswith("STATE_")]
        df_state_cols = df[state_cols]

        # Find the column with the "1" value for each row
        new_df = df.copy(True)
        new_df['STATE_ABB'] = df_state_cols.idxmax(axis=1).str.slice(start=6).astype(str)
        return new_df

    def add_month_col(df):
        # Extract only the state columns
        months_cols = [col for col in df.columns if col.startswith("MONTH_")]
        df_months_cols = df[months_cols]

        # Find the column with the "1" value for each row
        new_df = df.copy(True)
        new_df['MONTH'] = df_months_cols.idxmax(axis=1).str.slice(start=6).astype(str)
        return new_df

    df = add_state_abb_col(df)
    df = add_month_col(df)

    df = pd.merge(df, mean_df, on=['STATE_ABB', 'MONTH'], how="left")
    df = df.drop(columns=['STATE_ABB', 'MONTH'])
    df.fillna(df.mean(), inplace=True)
    return df


X_train = add_rainfall_data(X_train)
X_test = add_rainfall_data(X_test)



year_df_dict = {year: pd.read_csv("StormEvents_details-ftp_v1.0_d"+str(year)+"_c20170717.csv") for year in range(1996, 2015)}

import geopandas as gpd
from shapely.geometry import Point

# Load the fire dataset
fires = pd.read_csv("fires.csv")
# convert the date column to datetime
fires["date"] = pd.to_datetime(fires["date"])

# Convert the fire dataset into a GeoDataFrame
fires_gdf = gpd.GeoDataFrame(fires, geometry=gpd.points_from_xy(fires["longitude"], fires["latitude"]))

# Load the storms dataset
storms = pd.read_csv("storms.csv")
# convert start_date and end_date columns to datetime
storms["start_date"] = pd.to_datetime(storms["start_date"])
storms["end_date"] = pd.to_datetime(storms["end_date"])

# create a new column in the storms dataframe to store the result
storms["storm"] = False

# Convert the storms dataset into a GeoDataFrame
storms_gdf = gpd.GeoDataFrame(storms, geometry=gpd.points_from_xy(storms[["start_longitude","end_longitude"]], storms[["start_latitude","end_latitude"]]))

# Spatial join the two GeoDataFrames
join = gpd.sjoin(fires_gdf, storms_gdf, how="inner", op='intersects')

# group the data by fire and count the number of storms for each fire
fires_with_storms = join.groupby("index_left").size()

# Print the resulting fires dataframe
print(fires_with_storms)
